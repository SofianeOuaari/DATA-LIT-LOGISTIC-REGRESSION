{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMENTING LOGISTIC REGRESSION FROM SCRATCH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "class logistic_regression:\n",
    "    def __init__(self,lr,num_iter):\n",
    "        self.lr=lr\n",
    "        self.num_iter=num_iter \n",
    "        \n",
    "    def sigmoid(self,z):\n",
    "        return 1/(1+np.exp(-z))  \n",
    "    def loss(self,h,y): \n",
    "        return (-y*np.log(h)-(1-y)*np.log(1-h)).mean()  \n",
    "    def gradient(self,x,h,y): \n",
    "        return np.dot(x.T,(h-y))/len(y)\n",
    "    def fit(self,x,y): \n",
    "        self.weights=np.zeros(x.shape[1]) \n",
    "        for _ in range(self.num_iter):\n",
    "            z=np.dot(x,self.weights)\n",
    "            h=self.sigmoid(z)   \n",
    "            gradient=self.gradient(x,h,y) \n",
    "            self.weights-=self.lr*gradient \n",
    "    def predict(self,x,weights): \n",
    "        return np.round(self.sigmoid(np.dot(x,weights)))\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_file(data,num_iter): \n",
    "        global columns\n",
    "        columns=[]\n",
    "        normalization_param={\"min\":[],\"max\":[]} \n",
    "        columns_names=['Age','Workclass','fnlgwt','Education','Education Num','Marital Status',\n",
    "           'Occupation','Relationship','Race','Sex','Capital Gain','Capital Loss',\n",
    "           'Hours/Week','Country','Income']\n",
    "        train=pd.read_csv(data,sep=\",\",names=columns_names) \n",
    "        target=train[\"Income\"]  \n",
    "        target=target.astype(\"category\").cat.codes\n",
    "        train.drop(\"Income\",axis=1,inplace=True) \n",
    "        #categorical_features=train.select_dtypes(exclude=[\"bool\",\"int64\",\"Float64\"]).columns \n",
    "        train=pd.get_dummies(train) \n",
    "        num_features=train.select_dtypes(include=[\"int64\",\"float64\"]).columns \n",
    "        #Storing the min,max values\n",
    "        for num in num_features: \n",
    "            normalization_param[\"min\"].append(train[num].min()) \n",
    "            normalization_param[\"max\"].append(train[num].max()) \n",
    "        #Normalizing using the formula x=(x-min(x))/(max(x)-min(x))\n",
    "        train[num_features]=train[num_features].apply(lambda x:(x-x.min())/(x.max()-x.min()),axis=0)\n",
    "        columns=train.columns \n",
    "        model=logistic_regression(0.1,1000) \n",
    "        model.fit(train,target) \n",
    "        return model.weights,normalization_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data_file,weights,normalization_param):  \n",
    "    test=pd.read_csv(data_file,sep=\",\",names=['Age','Workclass','fnlgwt','Education','Education Num','Marital Status',\n",
    "           'Occupation','Relationship','Race','Sex','Capital Gain','Capital Loss',\n",
    "           'Hours/Week','Country','Income']) \n",
    "    test.dropna(axis=0,inplace=True)\n",
    "    test.drop(\"Income\",inplace=True,axis=1)\n",
    "    num_features=test.select_dtypes(include=[\"int64\",\"float64\"]).columns \n",
    "    for i in range(0,len(normalization_param)): \n",
    "        test[num_features[0]]=test[num_features[0]].apply(lambda x:(x-normalization_param[\"min\"][i])/(normalization_param[\"max\"][i]-normalization_param[\"min\"][i]))\n",
    "    test=pd.get_dummies(test)  \n",
    "    inter_col=np.intersect1d(np.array(test.columns),np.array(columns)) \n",
    "    col=set(columns)-set(inter_col)\n",
    "    test=test[inter_col] \n",
    "    for c in col: \n",
    "        test[c]=0\n",
    "    model=logistic_regression(lr=0.1,num_iter=1000) \n",
    "    y_pred=model.predict(test,weights) \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 47.5 s\n",
      "Wall time: 234 ms\n"
     ]
    }
   ],
   "source": [
    "%time weights,normalization_param=train_with_file(\"adult-training.csv\",1000) \n",
    "%time y_pred=classify(\"adult-test.csv\",weights,normalization_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
